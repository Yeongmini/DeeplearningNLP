{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "502c7437",
   "metadata": {},
   "source": [
    "7-8 케라스(Keras) 훑어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60894ec",
   "metadata": {},
   "source": [
    "1. 전처리(Preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe35cab",
   "metadata": {},
   "source": [
    "Tokenizer() : 토큰화와 정수 인코딩을 위해 사용된다. 훈련 데이터로부터 단어 집합을 생성하고, 해당 단어 집합으로 임의의 문장을 정수 인코딩하는 과정을 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913ae206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 :  [1, 2, 3, 4, 6, 7]\n",
      "단어 집합 :  {'the': 1, 'earth': 2, 'is': 3, 'an': 4, 'awesome': 5, 'place': 6, 'live': 7}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "train_text = \"The earth is an awesome place live\"\n",
    "\n",
    "# 단어 집합 생성\n",
    "tokenizer.fit_on_texts([train_text])\n",
    "\n",
    "# 정수 인코딩\n",
    "sub_text = \"The earth is an great place live\"\n",
    "sequences = tokenizer.texts_to_sequences([sub_text])[0]\n",
    "\n",
    "print(\"정수 인코딩 : \",sequences)\n",
    "print(\"단어 집합 : \",tokenizer.word_index )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a49a655",
   "metadata": {},
   "source": [
    "pad_sequence() : 전체 훈련 데이터에서 각 샘플의 길이는 서로 다를 수 있는데, 보통 숫자 0을 넣고 길이가 다른 샘플들의 길이를 맞춰준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6428ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [0, 7, 8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences([[1,2,3],[3,4,5,6],[7,8]], maxlen = 3, padding = 'pre') # padding = 'post' 로 하면 0이 앞에서부터 채운다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd10f62f",
   "metadata": {},
   "source": [
    "2. 워드 임베딩(Word Embedding)\n",
    "* 워드 임베딩이란 텍스트 내의 단어들을 밀집 벡터(dense vector)로 만드는 것을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba468b",
   "metadata": {},
   "source": [
    "Embedding() : 단어를 밀집 벡터로 만드는 역할을 한다. 인공 신경망 용어로는 임베딩 층을 만드는 역할을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e2a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 토큰화\n",
    "tokenized_text = [['Hope','to','see','you','soon'],['Nice','to','see','you','again']]\n",
    "\n",
    "# 2. 각 단어에 대한 정수 인코딩\n",
    "encoded_text = [[0,1,2,3,4],[5,1,2,3,6]]\n",
    "\n",
    "# 3. 위 정수 인코딩 데이터가 아래의 임베딩 층의 입력이 된다.\n",
    "vocab_size = 7\n",
    "embedding_dim = 2\n",
    "Embedding(vocab_size, embedding_dim, input_length = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce33e42",
   "metadata": {},
   "source": [
    "vocab_size = 단어 집합의 크기, 총 단어의 개수\\\n",
    "embedding_dim = 임베딩 벡터의 출력 차원, 결과로서 나오는 임베딩 벡터의 크기\\\n",
    "input_length = 입력 시퀀스의 길이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193ccf4",
   "metadata": {},
   "source": [
    "3. 모델링(Modeling)\n",
    "* Sequential() : 인공 신경망 챕터에서 배운 입력층, 은닉층, 출력층을 구성하기 위해서 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(...) # 층 추가\n",
    "model.add(...) # 층 추가\n",
    "model.add(...) # 층 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b149b0c5",
   "metadata": {},
   "source": [
    "Embedding()을 통해 생성하는 임베딩 층(embedding layer)을 추가하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, output_dim, input_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe905d2",
   "metadata": {},
   "source": [
    "전결합층(fully-connected layer)을 추가하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim = 3, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbefef",
   "metadata": {},
   "source": [
    "4. 컴파일(Compile)과 훈련(Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ea762",
   "metadata": {},
   "source": [
    "compile() : 모델을 기계가 이해할 수 있도록 컴파일한다. 손실 함수와 옵티마이저, 메트릭 함수를 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aec33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "vocab_size = 10000\n",
    "embedding_dim = 32\n",
    "hidden_units = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37d6b5",
   "metadata": {},
   "source": [
    "fit() : 모델을 학습한다. 즉, 모델의 훈련을 시작하는것을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce21fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 compile() 코드의 연장선상인 코드\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs = 10, batch_size = 32, verbose = 0, validation_data(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7e58e",
   "metadata": {},
   "source": [
    "validation_data(X_val, y_val) = 검증데이터를 사용한다. 검증데이터의 오차(loss)가 낮아지다가 높아지기 시작하면 이는 과적합의 신호이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f4f87",
   "metadata": {},
   "source": [
    "validation_split = validation_data와 동일하게 검증 데이터를 사용하기 위한 용도로 validation_data 대신 사용가능하다. 검증 데이터를 지정하는게 아닌 훈련 데이터와 레이블인 X_train, y_train에서 일정 비율 분리하여 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터의 20%를 검증 데이터로 사용\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size = 32, verbose = 0, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e32e9",
   "metadata": {},
   "source": [
    "verbose = 학습 중 출력되는 문구를 설정한다.\n",
    "- 0 : 아무 것도 출력하지 않는다. \n",
    "- 1 : 훈련의 진행도를 보여주는 진행 막대를 보여준다. \n",
    "- 2 : 미니 배치마다 손실 정보를 출력한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519da8b8",
   "metadata": {},
   "source": [
    "5. 평가(Evaluation)와 예측(Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72007d1",
   "metadata": {},
   "source": [
    "evaluate() : 테스트 데이터를 통해 학습한 모델에 대한 정확도를 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da75c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 fit() 코드의 연장선상인 코드\n",
    "model.evaluate(X_test, y_test, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879acfb",
   "metadata": {},
   "source": [
    "predict() : 임의의 입력에 대한 모델의 출력값을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 fit() 코드의 연장선상인 코드\n",
    "model.predict(X_input, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523c669",
   "metadata": {},
   "source": [
    "6. 모델의 저장(Save)과 로드(Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb9d455",
   "metadata": {},
   "source": [
    "save() : 인공 신경망 모델을 hdf5 파일에 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c018af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_name.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04835be",
   "metadata": {},
   "source": [
    "load_model() : 저장해둔 모델을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d4ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"model_name.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd05e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
